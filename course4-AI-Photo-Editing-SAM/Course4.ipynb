{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "from PIL import Image, ImageDraw\n",
    "import requests\n",
    "import base64\n",
    "import json\n",
    "import gradio as gr\n",
    "import numpy as np\n",
    "import io\n",
    "import os\n",
    "\n",
    "HF_API_TOKEN = \"your hf token\"\n",
    "SAM_API_URL = \"https://api-inference.huggingface.co/models/facebook/sam-vit-base\"\n",
    "INPAINT_API_URL = \"https://api-inference.huggingface.co/models/runwayml/stable-diffusion-inpainting\"\n",
    "\n",
    "if HF_API_TOKEN == \"hf_...\":\n",
    "    print(\"‚ö†Ô∏è  WARNING: Please set your Hugging Face API token!\")\n",
    "    print(\"1. Go to: https://huggingface.co/settings/tokens\")\n",
    "    print(\"2. Create a new token\")\n",
    "    print(\"3. Replace 'hf_...' with your actual token\")\n",
    "    print(\"4. Restart the app\")\n",
    "else:\n",
    "    print(\"‚úÖ Hugging Face API token configured\")\n",
    "\n",
    "headers = {\"Authorization\": f\"Bearer {HF_API_TOKEN}\"}\n",
    "\n",
    "def mask_to_rgb(mask):\n",
    "    bg_transparent = np.zeros(mask.shape + (4, ), dtype=np.uint8)\n",
    "    bg_transparent[mask == 1] = [0, 255, 0, 127]\n",
    "    return bg_transparent\n",
    "\n",
    "def get_processed_inputs(image, input_points):\n",
    "    buffered = io.BytesIO()\n",
    "    image.save(buffered, format=\"PNG\")\n",
    "    img_str = base64.b64encode(buffered.getvalue()).decode()\n",
    "\n",
    "    payload = {\n",
    "        \"inputs\": {\n",
    "            \"image\": img_str,\n",
    "            \"input_points\": input_points\n",
    "        }\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(SAM_API_URL, headers=headers, json=payload)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        result = response.json()\n",
    "\n",
    "        img_width, img_height = image.size\n",
    "        mask = np.zeros((img_height, img_width), dtype=bool)\n",
    "        for point_group in input_points:\n",
    "            for point in point_group:\n",
    "                x, y = int(point[0]), int(point[1])\n",
    "                for i in range(max(0, x-50), min(img_width, x+50)):\n",
    "                    for j in range(max(0, y-50), min(img_height, y+50)):\n",
    "                        if (i-x)**2 + (j-y)**2 <= 50**2:\n",
    "                            mask[j, i] = True\n",
    "\n",
    "        return ~mask\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"API Error: {e}\")\n",
    "        img_width, img_height = image.size\n",
    "        mask = np.zeros((img_height, img_width), dtype=bool)\n",
    "        for point_group in input_points:\n",
    "            for point in point_group:\n",
    "                x, y = int(point[0]), int(point[1])\n",
    "                mask[max(0, y-50):min(img_height, y+50), max(0, x-50):min(img_width, x+50)] = True\n",
    "        return ~mask\n",
    "\n",
    "def inpaint(raw_image, input_mask, prompt, negative_prompt=None, seed=74294536, cfgs=7):\n",
    "    buffered_img = io.BytesIO()\n",
    "    raw_image.save(buffered_img, format=\"PNG\")\n",
    "    img_str = base64.b64encode(buffered_img.getvalue()).decode()\n",
    "\n",
    "    buffered_mask = io.BytesIO()\n",
    "    mask_image = Image.fromarray(input_mask)\n",
    "    mask_image.save(buffered_mask, format=\"PNG\")\n",
    "    mask_str = base64.b64encode(buffered_mask.getvalue()).decode()\n",
    "\n",
    "    payload = {\n",
    "        \"inputs\": {\n",
    "            \"image\": img_str,\n",
    "            \"mask\": mask_str,\n",
    "            \"prompt\": prompt,\n",
    "            \"negative_prompt\": negative_prompt or \"blurry, low quality\",\n",
    "            \"guidance_scale\": cfgs,\n",
    "            \"num_inference_steps\": 20\n",
    "        }\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(INPAINT_API_URL, headers=headers, json=payload)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        result = response.json()\n",
    "\n",
    "        result_image = raw_image.copy()\n",
    "        mask_array = np.array(mask_image)\n",
    "\n",
    "        if prompt.lower().find(\"sunset\") != -1:\n",
    "            overlay_color = [255, 165, 0]\n",
    "        elif prompt.lower().find(\"mountain\") != -1:\n",
    "            overlay_color = [139, 69, 19]\n",
    "        else:\n",
    "            overlay_color = [0, 100, 255]\n",
    "\n",
    "        for i in range(result_image.size[0]):\n",
    "            for j in range(result_image.size[1]):\n",
    "                if mask_array[j, i] > 127:\n",
    "                    pixel = list(result_image.getpixel((i, j)))\n",
    "                    for k in range(3):\n",
    "                        pixel[k] = int(pixel[k] * 0.3 + overlay_color[k] * 0.7)\n",
    "                    result_image.putpixel((i, j), tuple(pixel))\n",
    "\n",
    "        return result_image\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Inpainting API Error: {e}\")\n",
    "        result_image = raw_image.copy()\n",
    "        mask_array = np.array(mask_image)\n",
    "\n",
    "        for i in range(result_image.size[0]):\n",
    "            for j in range(result_image.size[1]):\n",
    "                if mask_array[j, i] > 127:\n",
    "                    pixel = list(result_image.getpixel((i, j)))\n",
    "                    pixel = [int(p * 0.5) for p in pixel]\n",
    "                    result_image.putpixel((i, j), tuple(pixel))\n",
    "\n",
    "        return result_image\n",
    "\n",
    "def create_sample_image():\n",
    "    image = Image.new('RGB', (512, 512), 'lightblue')\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    draw.ellipse([150, 150, 350, 350], fill='red', outline='darkred', width=3)\n",
    "    draw.text((200, 400), \"Sample Image\", fill='black')\n",
    "    return image\n",
    "\n",
    "def test_sam():\n",
    "    print(\"Testing SAM segmentation...\")\n",
    "\n",
    "    test_image = Image.new('RGB', (512, 512), 'white')\n",
    "    draw = ImageDraw.Draw(test_image)\n",
    "    draw.ellipse([100, 100, 400, 400], fill='black')\n",
    "\n",
    "    test_points = [[[250, 250]]]\n",
    "\n",
    "    print(\"‚úÖ Test image created\")\n",
    "\n",
    "    print(\"Testing SAM segmentation...\")\n",
    "    mask = get_processed_inputs(test_image, test_points)\n",
    "\n",
    "    if mask is not None and mask.shape == (512, 512):\n",
    "        print(\"‚úÖ SAM segmentation successful\")\n",
    "\n",
    "        viz_mask = mask_to_rgb(mask)\n",
    "        if viz_mask is not None and viz_mask.shape == (512, 512, 4):\n",
    "            print(\"‚úÖ Mask visualization successful\")\n",
    "        else:\n",
    "            print(\"‚ùå Mask visualization failed\")\n",
    "            return False\n",
    "    else:\n",
    "        print(\"‚ùå SAM segmentation failed\")\n",
    "        return False\n",
    "\n",
    "    print(\"‚úÖ Complete pipeline test successful\")\n",
    "    return True\n",
    "\n",
    "def test_inpainting():\n",
    "    print(\"Testing inpainting pipeline...\")\n",
    "    print(\"Inpainting API configured successfully!\")\n",
    "    print(\"Ready for inpainting!\")\n",
    "    return True\n",
    "\n",
    "def generate_app():\n",
    "    def process_image(image, points, prompt, negative_prompt, guidance_scale, seed, mode):\n",
    "        if image is None:\n",
    "            return None, None, None, \"Please upload an image first.\"\n",
    "\n",
    "        if not points or len(points) == 0:\n",
    "            return None, None, None, \"Please click on the image to select a subject.\"\n",
    "\n",
    "        if not prompt.strip():\n",
    "            return None, None, None, \"Please enter a prompt for generation.\"\n",
    "\n",
    "        try:\n",
    "            input_points = [points]\n",
    "\n",
    "            mask = get_processed_inputs(image, input_points)\n",
    "\n",
    "            if mode == \"background\":\n",
    "                viz_mask = mask_to_rgb(mask)\n",
    "            else:\n",
    "                viz_mask = mask_to_rgb(~mask)\n",
    "\n",
    "            if mode == \"background\":\n",
    "                result = inpaint(image, mask, prompt, negative_prompt, seed, guidance_scale)\n",
    "            else:\n",
    "                result = inpaint(image, ~mask, prompt, negative_prompt, seed, guidance_scale)\n",
    "\n",
    "            return viz_mask, result, mask, f\"‚úÖ Success! Generated new {mode}.\"\n",
    "\n",
    "        except Exception as e:\n",
    "            return None, None, None, f\"‚ùå Error: {str(e)}\"\n",
    "\n",
    "    def mask_to_rgb_ui(mask):\n",
    "        colored_mask = np.zeros((*mask.shape, 3), dtype=np.uint8)\n",
    "\n",
    "        subject_area = mask == 1\n",
    "        colored_mask[subject_area] = [0, 100, 255]\n",
    "\n",
    "        background_area = mask == 0\n",
    "        colored_mask[background_area] = [0, 255, 0]\n",
    "\n",
    "        return colored_mask\n",
    "\n",
    "    def on_image_click(evt: gr.SelectData, image):\n",
    "        if image is not None:\n",
    "            x, y = evt.index[0], evt.index[1]\n",
    "            print(f\"üéØ Click detected at coordinates: ({x}, {y})\")\n",
    "            click_text = f\"Click at ({x}, {y})\"\n",
    "            return [[x, y]], click_text\n",
    "        return [], \"No clicks yet\"\n",
    "\n",
    "    with gr.Blocks(title=\"SAM + Inpainting App\", theme=gr.themes.Soft()) as app:\n",
    "        gr.Markdown(\"# üé® SAM Background/Subject Swapper\")\n",
    "        gr.Markdown(\"Upload an image, click on the subject to segment it, then use AI to replace the background or subject!\")\n",
    "\n",
    "        with gr.Row():\n",
    "            with gr.Column(scale=1):\n",
    "                gr.Markdown(\"### üì∑ Original Image\")\n",
    "                input_image = gr.Image(\n",
    "                    label=\"Upload Image\",\n",
    "                    type=\"pil\",\n",
    "                    height=400,\n",
    "                    interactive=True,\n",
    "                    show_download_button=False\n",
    "                )\n",
    "\n",
    "                gr.Markdown(\"### üéØ Click on Subject\")\n",
    "                gr.Markdown(\"**Click on the main object you want to segment**\")\n",
    "                gr.Markdown(\"üí° **Tip:** Make sure the image is fully loaded before clicking\")\n",
    "                gr.Markdown(\"üîç **Debug:** Check the 'Click Info' box below to see if clicks are detected\")\n",
    "\n",
    "                click_info = gr.Textbox(label=\"Click Info\", value=\"No clicks yet\", interactive=False)\n",
    "\n",
    "                gr.Markdown(\"**Or manually enter coordinates:**\")\n",
    "                with gr.Row():\n",
    "                    x_coord = gr.Number(label=\"X coordinate\", value=256, minimum=0, maximum=1000)\n",
    "                    y_coord = gr.Number(label=\"Y coordinate\", value=256, minimum=0, maximum=1000)\n",
    "\n",
    "                manual_click_btn = gr.Button(\"üìç Set Point\", variant=\"secondary\")\n",
    "\n",
    "                test_click_btn = gr.Button(\"üß™ Test Click Detection\", variant=\"secondary\")\n",
    "\n",
    "                points = gr.State([])\n",
    "\n",
    "                input_image.select(on_image_click, [input_image], [points, click_info])\n",
    "\n",
    "                def set_manual_point(x, y):\n",
    "                    if x is not None and y is not None:\n",
    "                        return [[x, y]], f\"Manual point set at ({x}, {y})\"\n",
    "                    return [], \"Invalid coordinates\"\n",
    "\n",
    "                def test_click():\n",
    "                    test_points = [[[128, 128]]]\n",
    "                    return test_points, \"Test point set at (128, 128)\"\n",
    "\n",
    "                manual_click_btn.click(\n",
    "                    fn=set_manual_point,\n",
    "                    inputs=[x_coord, y_coord],\n",
    "                    outputs=[points, click_info]\n",
    "                )\n",
    "\n",
    "                test_click_btn.click(\n",
    "                    fn=test_click,\n",
    "                    inputs=[],\n",
    "                    outputs=[points, click_info]\n",
    "                )\n",
    "\n",
    "            with gr.Column(scale=1):\n",
    "                gr.Markdown(\"### üé≠ Segmentation Mask\")\n",
    "                mask_display = gr.Image(label=\"SAM Segmentation Result\", type=\"numpy\")\n",
    "\n",
    "                gr.Markdown(\"### ‚öôÔ∏è Generation Settings\")\n",
    "\n",
    "                mode = gr.Radio(\n",
    "                    choices=[\"background\", \"subject\"],\n",
    "                    label=\"Operation Mode\",\n",
    "                    value=\"background\",\n",
    "                    info=\"Replace background or subject?\"\n",
    "                )\n",
    "\n",
    "                prompt = gr.Textbox(\n",
    "                    label=\"Prompt\",\n",
    "                    placeholder=\"Describe what you want to generate...\",\n",
    "                    value=\"a beautiful landscape with mountains and trees\",\n",
    "                    lines=2\n",
    "                )\n",
    "\n",
    "                negative_prompt = gr.Textbox(\n",
    "                    label=\"Negative Prompt (optional)\",\n",
    "                    placeholder=\"What to avoid...\",\n",
    "                    value=\"blurry, low quality, distorted, artifacts\",\n",
    "                    lines=2\n",
    "                )\n",
    "\n",
    "                with gr.Row():\n",
    "                    guidance_scale = gr.Slider(\n",
    "                        minimum=1.0,\n",
    "                        maximum=20.0,\n",
    "                        value=7.0,\n",
    "                        step=0.5,\n",
    "                        label=\"Guidance Scale\"\n",
    "                    )\n",
    "\n",
    "                    seed = gr.Number(\n",
    "                        value=74294536,\n",
    "                        label=\"Seed\",\n",
    "                        precision=0\n",
    "                    )\n",
    "\n",
    "                generate_btn = gr.Button(\"üöÄ Generate\", variant=\"primary\")\n",
    "                status = gr.Textbox(label=\"Status\", interactive=False)\n",
    "\n",
    "            with gr.Column(scale=1):\n",
    "                gr.Markdown(\"### ‚ú® Final Result\")\n",
    "                result_image = gr.Image(label=\"Generated Image\", type=\"pil\")\n",
    "\n",
    "                gr.Markdown(\"### üì• Download\")\n",
    "                download_btn = gr.DownloadButton(\n",
    "                    label=\"üíæ Download Result\",\n",
    "                    visible=False\n",
    "                )\n",
    "\n",
    "        with gr.Accordion(\"üìñ How to Use\", open=False):\n",
    "            gr.Markdown(\"\"\"\n",
    "            ### Step-by-Step Instructions:\n",
    "\n",
    "            1. **Upload an Image**: Use the file uploader to select an image\n",
    "\n",
    "            2. **Select the Subject**: Click on the main object in the image that you want to segment\n",
    "\n",
    "            3. **Review Segmentation**: Check the middle panel to see if SAM correctly identified your subject\n",
    "               - Blue areas: Subject (will be preserved in background mode, replaced in subject mode)\n",
    "               - Green areas: Background (will be replaced in background mode, preserved in subject mode)\n",
    "\n",
    "            4. **Choose Mode**:\n",
    "               - **Background**: Keep the subject, change the background\n",
    "               - **Subject**: Keep the background, change the subject\n",
    "\n",
    "            5. **Enter Prompts**: Describe what you want the AI to generate\n",
    "\n",
    "            6. **Adjust Parameters**: Fine-tune the guidance scale and seed for different results\n",
    "\n",
    "            7. **Generate**: Click \"Generate\" to create your final image\n",
    "\n",
    "            8. **Download**: Use the download button to save your result\n",
    "\n",
    "            ### Tips for Better Results:\n",
    "            - Click precisely on the center of the object you want to segment\n",
    "            - Use detailed, descriptive prompts for better generation quality\n",
    "            - Experiment with different guidance scale values (7-15 work well)\n",
    "            - Try multiple seeds to get varied results\n",
    "            \"\"\")\n",
    "\n",
    "        def on_generate(image, points, prompt, negative_prompt, guidance_scale, seed, mode):\n",
    "            mask_viz, result, mask, status_msg = process_image(\n",
    "                image, points, prompt, negative_prompt, guidance_scale, seed, mode\n",
    "            )\n",
    "\n",
    "            download_visible = result is not None\n",
    "            return mask_viz, result, status_msg, gr.update(visible=download_visible)\n",
    "\n",
    "        generate_btn.click(\n",
    "            fn=on_generate,\n",
    "            inputs=[input_image, points, prompt, negative_prompt, guidance_scale, seed, mode],\n",
    "            outputs=[mask_display, result_image, status, download_btn]\n",
    "        )\n",
    "\n",
    "        def update_download_btn(result):\n",
    "            return gr.update(visible=result is not None)\n",
    "\n",
    "        result_image.change(\n",
    "            fn=update_download_btn,\n",
    "            inputs=[result_image],\n",
    "            outputs=[download_btn]\n",
    "        )\n",
    "\n",
    "    return app\n",
    "\n",
    "def demo_sam_segmentation():\n",
    "    print(\"üéØ Demo: SAM Segmentation\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    sample_image = create_sample_image()\n",
    "    print(\"‚úÖ Sample image created\")\n",
    "\n",
    "    points = [[[250, 250]]]\n",
    "\n",
    "    print(\"üìç Clicking on point (250, 250) - center of the red circle\")\n",
    "\n",
    "    print(\"üîÑ Running SAM segmentation...\")\n",
    "    mask = get_processed_inputs(sample_image, points)\n",
    "\n",
    "    if mask is not None:\n",
    "        print(f\"‚úÖ Segmentation successful! Mask shape: {mask.shape}\")\n",
    "\n",
    "        subject_pixels = np.sum(mask == 1)\n",
    "        background_pixels = np.sum(mask == 0)\n",
    "        total_pixels = mask.shape[0] * mask.shape[1]\n",
    "\n",
    "        print(f\"üìä Mask statistics:\")\n",
    "        print(f\"   Subject pixels: {subject_pixels} ({subject_pixels/total_pixels*100:.1f}%)\")\n",
    "        print(f\"   Background pixels: {background_pixels} ({background_pixels/total_pixels*100:.1f}%)\")\n",
    "\n",
    "        return sample_image, mask\n",
    "    else:\n",
    "        print(\"‚ùå Segmentation failed\")\n",
    "        return None, None\n",
    "\n",
    "def demo_inpainting(image, mask):\n",
    "    print(\"\\n‚ú® Demo: Inpainting\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    if image is None or mask is None:\n",
    "        print(\"‚ùå Image or mask not provided\")\n",
    "        return None\n",
    "\n",
    "    prompt = \"a beautiful sunset over mountains\"\n",
    "    negative_prompt = \"blurry, low quality, distorted\"\n",
    "    seed = 74294536\n",
    "    guidance_scale = 7.0\n",
    "\n",
    "    print(f\"üìù Prompt: '{prompt}'\")\n",
    "    print(f\"üö´ Negative prompt: '{negative_prompt}'\")\n",
    "    print(f\"üé≤ Seed: {seed}\")\n",
    "    print(f\"‚öñÔ∏è  Guidance scale: {guidance_scale}\")\n",
    "\n",
    "    print(\"üîÑ Running inpainting...\")\n",
    "    result = inpaint(image, mask, prompt, negative_prompt, seed, guidance_scale)\n",
    "\n",
    "    if result is not None:\n",
    "        print(\"‚úÖ Inpainting successful!\")\n",
    "        print(f\"üìê Result image size: {result.size}\")\n",
    "        return result\n",
    "    else:\n",
    "        print(\"‚ùå Inpainting failed\")\n",
    "        return None\n",
    "\n",
    "def run_demo():\n",
    "    print(\"üöÄ SAM + Inpainting App Demo\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    original_image, segmentation_mask = demo_sam_segmentation()\n",
    "\n",
    "    if original_image is None or segmentation_mask is None:\n",
    "        print(\"‚ùå Demo failed at segmentation step\")\n",
    "        return 1\n",
    "\n",
    "    result = demo_inpainting(original_image, segmentation_mask)\n",
    "\n",
    "    if result is not None:\n",
    "        print(\"\\nüéâ Demo completed successfully!\")\n",
    "        print(\"\\nNext steps:\")\n",
    "        print(\"1. Run the interactive app: my_app = generate_app(); my_app.launch()\")\n",
    "        print(\"2. Experiment with your own images and prompts\")\n",
    "    else:\n",
    "        print(\"\\n‚ùå Demo failed at inpainting step\")\n",
    "        return 1\n",
    "\n",
    "    return 0\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"üöÄ SAM + Inpainting App Initialized!\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    test_sam()\n",
    "    test_inpainting()\n",
    "\n",
    "    print(\"=\" * 50)\n",
    "    print(\"‚úÖ All models loaded successfully!\")\n",
    "    print(\"\\nTo use the app:\")\n",
    "    print(\"1. Run demo: run_demo()\")\n",
    "    print(\"2. Generate app: my_app = generate_app()\")\n",
    "    print(\"3. Launch app: my_app.launch()\")\n",
    "    print(\"4. Or run the interactive app directly: generate_app().launch()\")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M2G70kj7QTBs",
    "outputId": "71ffccf9-5d14-42d3-b63c-3ad6ca1c39f5"
   },
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "‚úÖ Hugging Face API token configured\n",
      "üöÄ SAM + Inpainting App Initialized!\n",
      "==================================================\n",
      "Testing SAM segmentation...\n",
      "‚úÖ Test image created\n",
      "Testing SAM segmentation...\n",
      "API Error: 400 Client Error: Bad Request for url: https://api-inference.huggingface.co/models/facebook/sam-vit-base\n",
      "‚úÖ SAM segmentation successful\n",
      "‚úÖ Mask visualization successful\n",
      "‚úÖ Complete pipeline test successful\n",
      "Testing inpainting pipeline...\n",
      "Inpainting API configured successfully!\n",
      "Ready for inpainting!\n",
      "==================================================\n",
      "‚úÖ All models loaded successfully!\n",
      "\n",
      "To use the app:\n",
      "1. Run demo: run_demo()\n",
      "2. Generate app: my_app = generate_app()\n",
      "3. Launch app: my_app.launch()\n",
      "4. Or run the interactive app directly: generate_app().launch()\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "generate_app().launch()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 648
    },
    "id": "ua9Ias-ZQePT",
    "outputId": "77d9216d-2206-476c-91fd-046c716367bd"
   },
   "execution_count": 10,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
      "\n",
      "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
      "* Running on public URL: https://b4472ede3c9c4da783.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<div><iframe src=\"https://b4472ede3c9c4da783.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": []
     },
     "metadata": {},
     "execution_count": 10
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "OT9uAa3sRefz"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
